# -*- coding: utf-8 -*-
"""ForestFires_ChristianRamirez.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/127wpqcyGOEMOFDMobqR3-tYvbfVIS2-x
"""



"""**First Delivery**

Regression problem

Forest Fires Dataset (Indices  from the  Fire Weather Index System:  Drought Code DC, Duff Moisture Code DMC and Fine Fuel Moisture Code FFMC)

by Christian Ramirez

Tasks included:


1.   Analyze and understand the provided dataset through Exploratory Data Analysis.
2.   Determine the insight you want to address with a machine learning model.

1.    Identify why an MLOps strategy is needed for this dataset. (Module 1)
2.   Design the pipeline architecture for this new machine learning initiative.

1.   Create a baseline model to address prediction tasks (classification, regression, etc.) related to the question. This model does not need high accuracy, recall, or F1 score; the goal is to create a quick model for iteration. (Module 4)









"""

##Module 1 EDA
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset (https://archive.ics.uci.edu/dataset/162/forest+fires)
data_path = "forestfires.csv"
df = pd.read_csv(data_path)

# Displaying the first few data rows
print(df.head())

#Describing data to get a better idea of data
print(df.describe())

correlation_matrix = df[['DC', 'DMC', 'FFMC', 'area']].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

#Dist plots
plt.figure(figsize=(12, 6))
plt.subplot(2, 2, 1)
sns.histplot(df['DC'], bins=30, kde=True, color='blue')
plt.title('Drought Code Distribution')

plt.subplot(2, 2, 2)
sns.histplot(df['DMC'], bins=30, kde=True, color='red')
plt.title('Duff Moisture Code Distribution')

plt.subplot(2, 2, 3)
sns.histplot(df['FFMC'], bins=30, kde=True, color='green')
plt.title('Fine Fuel Moisture Code Distribution')

plt.subplot(2, 2, 4)
sns.histplot(df['area'], bins=30, kde=True, color='orange')
plt.title('Burned Area Distribution')
plt.show()

#scatter plots
plt.figure(figsize=(12, 6))
plt.subplot(1, 3, 1)
sns.scatterplot(x='DC', y='area', data=df, color='blue')
plt.title('Drought Code vs Burned Area')

plt.subplot(1, 3, 2)
sns.scatterplot(x='DMC', y='area', data=df, color='red')
plt.title('Duff Moisture Code vs Burned Area')

plt.subplot(1, 3, 3)
sns.scatterplot(x='FFMC', y='area', data=df, color='green')
plt.title('Fine Fuel Moisture Code vs Burned Area')
plt.show()

#Module 2
#Determine the insight you want to address with a machine learning model

#TARGET: Predict the burned area of forest fires by using meteorological

#Module 3
#Identify why an MLOps strategy is needed for this dataset. (Module 1)
'''
An MLOps strategy should be use for ensuring their reliability, scalability, maintainability and
compliance with regulatory standards, which in the context of predicting forest fires
 where accuracy and time from prediction to action are most important.
'''

'''
Module 4
Design the pipeline architecture for this new machine learning initiative.

AND

Module 5
Create a baseline model to address prediction tasks (classification, regression, etc.) related to the question.
This model does not need high accuracy, recall, or F1 score; the goal is to create a quick model for iteration. (Module 4)
'''

# Importing libraries
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score


#Loading and spliting data
def load_and_split_data(data_path):
    # Loading data
    df = pd.read_csv(data_path)

    # Selected features (DC, DMC, FFMC) and target variable (area)
    X = df[['DC', 'DMC', 'FFMC']]  # Selected features
    y = df['area']  # Target variable

    # Split data into training and testing sets (80% training, 20% testing)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

#Training Model
def train_model(X_train, y_train):
    # Using a Random Forest regression model
    model = RandomForestRegressor()

    # Training the model using training data
    model.fit(X_train, y_train)

    return model

# Evaluating Model
def evaluate_model(model, X_test, y_test):
    # Predicting burned areas
    y_pred = model.predict(X_test)

    # Mean Squared Error and R-squared score
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    return mse, r2, y_pred

# Main function
def main():
    # Step 1: Loading and spliting data
    X_train, X_test, y_train, y_test = load_and_split_data(data_path)

    # Step 2: Training Model
    model = train_model(X_train, y_train)

    # Step 3: Evaluating Model
    mse, r2, y_pred = evaluate_model(model, X_test, y_test)
    print("Predicted Area:", y_pred)
    print("Mean Squared Error:", mse)
    print("R-squared Score:", r2)


# Executing main function
if __name__ == "__main__":
    main()

